{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbin0 = np.load('/home/jua/corsika/run/energy_var/npz/0427/bin/gamma_energy_bin0_all.npz')\n",
    "pbin0 = np.load('/home/jua/corsika/run/energy_var/npz/0427/bin/proton_energy_bin0_all.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gim = gbin0['image'][:]\n",
    "pim = pbin0['image'][:]\n",
    "#gim = torch.tensor(gim).float() \n",
    "#pim = torch.tensor(gim).float() \n",
    "gim_label = torch.zeros([len(gim)])\n",
    "pim_label = torch.ones([len(pim)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.vstack((gim[:int(len(gim)*0.7)],pim[:int(len(pim)*0.7)]))\n",
    "test_images  = np.vstack((gim[int(len(gim)*0.7):],pim[int(len(pim)*0.7):]))\n",
    "train_labels = np.hstack((gim_label[:int(len(gim)*0.7)],pim_label[:int(len(pim)*0.7)]))\n",
    "test_labels  = np.hstack((gim_label[int(len(gim)*0.7):],pim_label[int(len(pim)*0.7):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = torch.tensor(train_images).float()\n",
    "train_labels = torch.tensor(train_labels).float()\n",
    "test_images  = torch.tensor(test_images).float()\n",
    "test_labels  = torch.tensor(test_labels).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = ([(train_images[i],train_labels[i])for i in range(len(train_labels))])\n",
    "test_sets = ([(test_images[i],test_labels[i])for i in range(len(test_labels))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_sets, batch_size=4, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_sets, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 64, kernel_size=7)\n",
    "        self.batch1 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5)    \n",
    "        #self.batch2 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(64*6*6, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.batch1(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #x = self.batch2(x)\n",
    "        x = x.view(-1, 64*6*6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(4, 64, kernel_size=7)\n",
    "batch = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "conv2 = nn.Conv2d(64, 64, kernel_size=5)\n",
    "conv2_drop = nn.Dropout2d()\n",
    "pool = nn.MaxPool2d(2,2)\n",
    "fc1 = nn.Linear(64*6*6, 120)\n",
    "fc2 = nn.Linear(120, 84)\n",
    "fc3 = nn.Linear(84, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pool(F.relu(conv2(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = batch(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.view(-1,64*6*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.relu(fc3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1087],\n",
       "        [0.0000, 0.3208],\n",
       "        [0.0000, 0.1081],\n",
       "        [0.0766, 0.0990],\n",
       "        [0.0000, 0.1112],\n",
       "        [0.0000, 0.1100],\n",
       "        [0.0123, 0.0874],\n",
       "        [0.0000, 0.1094],\n",
       "        [0.0000, 0.1094],\n",
       "        [0.0000, 0.1090],\n",
       "        [0.0000, 0.1106],\n",
       "        [0.0368, 0.1559],\n",
       "        [0.0000, 0.1090],\n",
       "        [0.0000, 0.1083],\n",
       "        [0.0000, 0.1177],\n",
       "        [0.0000, 0.1116]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.001, momentum=0.9)\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net\n",
    "since = time.time()\n",
    "best_model_wts = model.state_dict()\n",
    "best_acc = 0.0\n",
    "train_losses = []\n",
    "train_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = exp_lr_scheduler\n",
    "scheduler.step()\n",
    "model.train(True)\n",
    "running_loss = 0.0\n",
    "running_corrects= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in trainloader:\n",
    "    inputs, labels = data\n",
    "    inputs = Variable(inputs)\n",
    "    labels = Variable(labels)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    loss = criterion(outputs, labels.long())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += loss.data\n",
    "    running_corrects += torch.sum(preds==labels.long())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        epoch_loss = running_loss/len(train_images)\n",
    "        epoch_acc = float(running_corrects)/len(train_images)\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracy.append(epoch_acc)\n",
    "        print('Train Loss: {:.4f}, Acc : {:.4f}'.format( epoch_loss, epoch_acc))\n",
    "        if epoch_acc>best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_sts = model.state_dict()\n",
    "    print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\"Training complete in {:.0f}s\".format(time_elapsed//60, time_elapsed%60))\n",
    "    print(\"Best Acc: {:4f}\".format(best_acc))\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model,train_losses, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, criterion, optimizer, scheduler, num_epochs=1):\n",
    "    since = time.time()\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    train_losses = []\n",
    "    train_accuracy = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs-1))\n",
    "        print('-'*10)\n",
    "        #optimizer.step()\n",
    "        scheduler.step()\n",
    "        model.train(True)\n",
    "        running_loss = 0.0\n",
    "        running_corrects= 0\n",
    "\n",
    "        for data in trainloader:\n",
    "            inputs, labels = data\n",
    "            #inputs = Variable(inputs.cuda())\n",
    "            #labels = Variable(labels.cuda())\n",
    "            inputs = Variable(inputs)\n",
    "            labels = Variable(labels)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.data\n",
    "            running_corrects += torch.sum(preds==labels.long())\n",
    "    \n",
    "        epoch_loss = running_loss/len(train_images)\n",
    "        epoch_acc = float(running_corrects)/len(train_images)\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracy.append(epoch_acc)\n",
    "        print('Train Loss: {:.4f}, Acc : {:.4f}'.format( epoch_loss, epoch_acc))\n",
    "        if epoch_acc>best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_sts = model.state_dict()\n",
    "    print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\"Training complete in {:.0f}s\".format(time_elapsed//60, time_elapsed%60))\n",
    "    print(\"Best Acc: {:4f}\".format(best_acc))\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model,train_losses, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "Train Loss: 0.1738, Acc : 0.5008\n",
      "Epoch 1/4\n",
      "----------\n",
      "Train Loss: 0.1737, Acc : 0.5000\n",
      "Epoch 2/4\n",
      "----------\n",
      "Train Loss: 0.1738, Acc : 0.4996\n",
      "Epoch 3/4\n",
      "----------\n",
      "Train Loss: 0.1738, Acc : 0.4996\n",
      "Epoch 4/4\n",
      "----------\n",
      "Train Loss: 0.1736, Acc : 0.5015\n",
      "\n",
      "Training complete in 0s\n",
      "Best Acc: 0.501536\n"
     ]
    }
   ],
   "source": [
    "net, train_losses, train_accuracy = train_model(net, trainloader, criterion, optimizer, exp_lr_scheduler,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss = 0.0\n",
    "running_corrects= 0\n",
    "for data in trainloader:\n",
    "    inputs, labels = data\n",
    "    inputs = Variable(inputs)\n",
    "    labels = Variable(labels)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs)\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    loss = criterion(outputs, labels.long())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += loss.data\n",
    "    running_corrects += torch.sum(preds==labels.long())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pool(F.relu(conv1(inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pool(F.relu(conv2(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.view(-1, 16*6*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.relu(fc2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs = net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss =criterion(outputs, labels.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7064)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(4, 6, kernel_size=7)\n",
    "conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "conv2_drop = nn.Dropout2d()\n",
    "pool = nn.MaxPool2d(2,2)\n",
    "fc1 = nn.Linear(16*6*6, 120)\n",
    "fc2 = nn.Linear(120, 84)\n",
    "fc3 = nn.Linear(84, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 6, kernel_size=7)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(16*6*6, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*6*6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0792e+00,  6.7448e-01],\n",
       "        [-4.9209e+00,  1.8319e-01],\n",
       "        [-4.6647e-01, -5.5905e-01],\n",
       "        [-6.3199e-01, -1.2556e-01],\n",
       "        [-1.1133e+00, -2.2625e-02],\n",
       "        [-5.1064e-01, -1.2066e-03],\n",
       "        [-5.3242e-01, -2.2281e-01],\n",
       "        [-7.4729e-01, -1.2443e-01],\n",
       "        [-6.3355e-01, -2.9101e-01],\n",
       "        [-3.7511e-01,  1.5296e-02],\n",
       "        [-6.5265e+00,  2.5013e+00],\n",
       "        [-9.4022e-01, -2.1924e-01],\n",
       "        [-5.4421e-01,  5.0286e-01],\n",
       "        [-4.1779e+00,  2.8329e+00],\n",
       "        [-8.4374e+00,  4.1572e+00],\n",
       "        [-9.9679e+00,  9.5558e+00]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
