{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from version_model.model_list import *\n",
    "from model_structure import save_model_structure\n",
    "from plotting import plottingLossAcc, roc\n",
    "from save_log import save_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = {}\n",
    "# normtype : minmax or std\n",
    "normtype = 'std'\n",
    "for i in range(1,10):\n",
    "    bins[i] = np.load(\"/home/jua/SWGO/square/data/{}/bin{}.npz\".format(normtype, i))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "images = bins[n]['image'][:]\n",
    "labels = bins[n]['label'][:]\n",
    "\n",
    "images = torch.tensor(images).float()\n",
    "labels = torch.tensor(labels).float()\n",
    "\n",
    "sets = [(images[i],labels[i])for i in range(len(labels))]\n",
    "shuffle(sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = sets[:int(len(sets)*0.5)]\n",
    "valid_sets = sets[int(len(sets)*0.5):int(len(sets)*0.75)]\n",
    "test_sets = sets[int(len(sets)*0.75):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 4\n",
    "trainloader = torch.utils.data.DataLoader(train_sets, batch_size=batchsize, shuffle=True, num_workers=2)\n",
    "validloader = torch.utils.data.DataLoader(valid_sets, batch_size=batchsize, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_sets, batch_size=batchsize, shuffle=True, num_workers=2)\n",
    "dataloader = {'train':trainloader, 'valid':validloader, 'test':testloader}\n",
    "datasize = {'train': len(train_sets), 'valid':len(valid_sets), 'test':len(test_sets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Train : 49045, # of valid : 24523, # of Test : 24523\n"
     ]
    }
   ],
   "source": [
    "print('# of Train : {}, # of valid : {}, # of Test : {}'.format(datasize['train'],datasize['valid'],datasize['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        # print('Reset parameters of Linear')\n",
    "        m.reset_parameters()\n",
    "\n",
    "def freeze_conv(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        # print('Freeze parameters of Conv2d')\n",
    "        m.weight.requires_grad = False\n",
    "        if m.bias is not None:\n",
    "            m.bias.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model5(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Model5()\n",
    "\n",
    "if n > 9:\n",
    "    net.load_state_dict(torch.load(\"save_model/best/best_B1_51220200527-151056.pth\"))  \n",
    "    net.apply(weight_init)\n",
    "    net.apply(freeze_conv)\n",
    "\n",
    "device=torch.device('cuda')\n",
    "net.to(device)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0003\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum=0.9)\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)\n",
    "#exp_lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',factor=0.1,verbose=True,patience=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "inputsize = 4\n",
    "classes = {0:'gamma',1:'proton'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, dataloader, criterion, optimizer, scheduler, n, batchsize, num_epochs=1, device=torch.device('cuda')):\n",
    "    \n",
    "    since = time.time()\n",
    "    best_net_wts = net.state_dict()\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    losses = {'train':[],'valid':[]}\n",
    "    accuracy = {'train':[],'valid':[]}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print( )\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs-1))\n",
    "        print('-'*10)\n",
    "        for phase in ['train','valid']:\n",
    "            if phase=='train':\n",
    "                net.train(True)\n",
    "            else:\n",
    "                net.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects= 0\n",
    "            ep_running_loss = 0.0\n",
    "            ep_running_corrects = 0\n",
    "            device = torch.device('cuda')\n",
    "            for i, data in enumerate(dataloader[phase]):\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                if phase=='train':\n",
    "                    optimizer.zero_grad()\n",
    "                logits = net(inputs)\n",
    "                outputs = logits.sigmoid()\n",
    "                #outputs = net(inputs)\n",
    "                #_, preds = torch.max(outputs.data, 1)\n",
    "                preds = outputs>threshold\n",
    "                loss = criterion(logits, labels.view(-1,1).float())\n",
    "                if phase=='train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                                       \n",
    "                running_loss += loss.data\n",
    "                ep_running_loss += loss.data\n",
    "                target = labels.view(-1,1)>threshold\n",
    "                running_corrects += torch.sum(preds==target)\n",
    "                ep_running_corrects += torch.sum(preds==target)\n",
    "                               \n",
    "                # Tensor Board \n",
    "                n_times = 10\n",
    "                if i%n_times==9:\n",
    "                    writer.add_scalar('{} loss'.format(phase),\n",
    "                                     running_loss/(n_times),\n",
    "                                     epoch*len(dataloader[phase])+i)\n",
    "                    writer.add_scalar('{} Accuracy'.format(phase),\n",
    "                                     float(running_corrects)/(n_times*batchsize),\n",
    "                                     epoch*len(dataloader[phase])+i)                  \n",
    "                    running_loss = 0.0\n",
    "                    running_corrects = 0\n",
    "                \n",
    "            writer.close()\n",
    "            epoch_loss = float(ep_running_loss)/float(len(dataloader[phase]))\n",
    "            epoch_acc = float(ep_running_corrects)/float(datasize[phase])\n",
    "            losses[phase].append(epoch_loss)\n",
    "            accuracy[phase].append(epoch_acc)\n",
    "            print('{} Loss: {:.4f}, Acc : {:.4f}'.format( phase, epoch_loss, epoch_acc))    \n",
    "            if phase == 'valid':\n",
    "                scheduler.step(losses['valid'][-1])\n",
    "                #scheduler.step()\n",
    "            if phase=='valid' and epoch_acc>best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_net_wts = net.state_dict()\n",
    "        \n",
    "    print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\"Training complete in {:.0f}s\".format(time_elapsed//60, time_elapsed%60))\n",
    "    print(\"Best Acc: {:4f}\".format(best_acc))\n",
    "    net.load_state_dict(best_net_wts)\n",
    "    if best_acc > 0.85:\n",
    "        modellogdir = \"save_model/best/best_B{}_512\".format(n) + now.strftime(\"%Y%m%d-%H%M%S\") + \".pth\"\n",
    "        torch.save(net.state_dict(), modellogdir)\n",
    "        save_log(losses, accuracy, num_epochs, n)\n",
    "        save_model_structure(net, '5')\n",
    "    return net,losses,accuracy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(testloader,batchsize,device=torch.device('cuda')):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_score = np.array([])\n",
    "    y = np.array([])\n",
    "    test_losses = []\n",
    "    for data in testloader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        labels = labels.view(-1,1)\n",
    "        logits = net(inputs)\n",
    "        outputs = logits.sigmoid()\n",
    "        preds = outputs>threshold     \n",
    "        loss = criterion(logits, labels.view(-1,1).float())\n",
    "        y_score = np.append(y_score,outputs.data.cpu().detach().numpy())\n",
    "        y = np.append(y,labels.cpu().numpy())\n",
    "        test_losses.append(loss.data/batchsize)\n",
    "        total += labels.size(0)\n",
    "        target = labels.view(-1,1)>threshold\n",
    "        correct += torch.sum(preds==target)\n",
    "    return y, y_score, correct, total, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0/19\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "logdir = \"runs/bin{}/\".format(n) + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = SummaryWriter(logdir)\n",
    "net,losses,accuracy = train_model(net, dataloader, criterion, optimizer,exp_lr_scheduler, n, batchsize, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plottingLossAcc(losses,accuracy, n,(0,len(losses['train'])+1,0,0.75),(0,len(accuracy['train'])+1,0.55,1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,y_score,correct,total,test_losses = test(testloader,batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "roc(y,y_score,correct,total,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum(each.numel() for each in net.parameters() if each.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "51*51*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [# of epoch] : 20\n",
    "#modellogdir = \"save_model/best/best_B{}_512\".format(n) + now.strftime(\"%Y%m%d-%H%M%S\") + \".pth\"\n",
    "#torch.save(net.state_dict(), modellogdir)\n",
    "#save_log(losses, accuracy, 20, n)\n",
    "#save_model_structure(net, '1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
